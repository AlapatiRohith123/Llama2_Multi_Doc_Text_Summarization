{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers einops accelerate langchain bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/kaggle/input/datasetSecure/data.json', 'r') as file:\n",
    "    datasec = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=datasec[\"token\"]\n",
    "command = f\"huggingface-cli login --token {token}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch -U\n",
    "!pip install transformers accelerate git+https://github.com/kashif/diffusers.git@a3dc21385b7386beb3dab3a9845962ede6765887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "model1 = \"\"\n",
    "# model = \"soundarya2873/llama-2-7b-chat-finetuned1\"\n",
    "model=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# model=\"alapatirohith/llama-2-7b-chat-finetuned1_\"\n",
    "# model=\"Dhanunjaysuppa/llama-2-7b-chat-finetuned1_fun\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipeline = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer= tokenizer,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=\"auto\",\n",
    "                max_new_tokens = 512,\n",
    "                do_sample=True,\n",
    "                top_k=30,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \"6606ec4f2e72622b76112689\"\n",
    "text = r\"\"\"Types  of Data  \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "Flat Files: Flat files are the most  common  data source  for data minin g \n",
    "algorithms, especially at the research level.  \n",
    "Flat files are simple data files in text or  binary f ormat with a structure \n",
    "known by the data mining algorithm to be applied.  \n",
    "The data in these files can  be transactions,  time-series  data,  scientific  \n",
    "measurements,  etc. \n",
    "Relational Databases : A relational database consists of a set of tables \n",
    "containing either  values of entity attributes, or values of  attributes from \n",
    "entity relationships.  \n",
    "Tables have  columns and rows, where columns represent attributes and \n",
    "rows represent tuples.  \n",
    "A tuple in a relational table corresponds to either an object or a relationship \n",
    "between  objects  and is identified  by a set of attribute  values  representing  a \n",
    "unique  key. \n",
    "  \n",
    "In following figure,  it presents some relations Customer, Items, and Borrow \n",
    "representing  business activity in a video store. These relations are just a \n",
    "subset of what could be a  database  for the video  store  and is  given  as an \n",
    "example.  \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "The most used  query language for relational database is SQL, w hich allows  \n",
    "retrieval and manipulation of the data stored in the tables, as well as the \n",
    "calculation of  aggregate fu nctions such as average, sum, min, max and \n",
    "count. For instance, a n SQL  query  to select  the videos  grouped by  category  \n",
    "would  be: \n",
    "SELECT  coun t (*) FROM  Items  WHERE  type=video  GROUP  BY \n",
    "category.  \n",
    "Data  mining  algorithms  using  relational  databases  can be more  versatile  \n",
    "than data mining algorithms s pecifically written for flat files, since they can \n",
    "take advantage of the structure inherent to r elational databases.  \n",
    "Transactional  databases : In general,  a transactional  database  consists  of \n",
    "a flat file where  each record  represents  a transaction.  \n",
    "A transaction typically includes a unique transaction identity nu mber (trans \n",
    "ID), and a  list of the items  making up  the transaction  (such  as items  \n",
    "purchased  in a store)  as shown  below : \n",
    " \n",
    "        \n",
    " \n",
    "     SALES  \n",
    " \n",
    "Trans -ID List of item ID’s  \n",
    "T100  \n",
    "……..  I1, I3, I8 \n",
    "………  \n",
    " \n",
    "Spatial Database : It contains  spatial -related data, which may be \n",
    "represented in the  form of raster or vector data.  \n",
    "Raster data consists of n -dimensional bit maps or pixel  maps,  and vector  \n",
    "data are represented  by lines,  points,  polygons  or other  kinds  of processed \n",
    "primitives . \n",
    "Examples of spatial databases include geographical (map)  databases,  VLSI  \n",
    "chip designs,  and medical  and satellite  images  databases.  \n",
    "Data  Warehouse : A data warehouse is a repository of information \n",
    "collected from multiple sources, stored  under a unified schema, and which \n",
    "usually resides at a single site. Data warehouses are  constructed via a \n",
    "process of data cleansing, data transformation, data integration, data  \n",
    "loading, and periodic data refreshing.  \n",
    " \n",
    " \n",
    "To facilitate  decision  making,  the data in a data warehouse  are organ ized \n",
    "around  major  subje cts, such as customer,  item,  supplier,  and activity.  The data \n",
    "are stored  to provide  infor mation  from  a historical  perspective  and are \n",
    "typically  summarize d. \n",
    " \n",
    "A data war ehouse is usually modeled by a multidimensional database \n",
    "structure, where  each dimensi on corresponds to  an attribute or  a set  of \n",
    "attributes in  the schem a, and each  cell stores th e value of some aggregate \n",
    "measure, such  as count or sales amoun t. The actual physical stru cture of a \n",
    "data warehouse may be a relational data store or a  multidimensional data cube. \n",
    "It provides a multidimensional view of data and allows the  precom putation  \n",
    "and fast accessin g of summarize d data.  \n",
    " \n",
    "Multimedia  Database : It stores  images,  audio,  and video  data,  and is used in \n",
    "applications  such as picture  content -based  retrieval,  voice -mail systems,  video -\n",
    "on- demand systems,  the World  Wide  Web,  and speech -based  user interfaces.  \n",
    " \n",
    "Time -Series Databases: Time -series databases contain time related data such \n",
    "stock  market data or logged activities. These databases usually have a continuous \n",
    "flow of new  data coming in, which sometimes causes the need for a challenging \n",
    "real time analysis.  Data mining in such databases commonly includes the study of \n",
    "trends and correlations  between  evolutions  of different  variables,  as well as the \n",
    "prediction  of trends  and movements  of the variables  in time.  \n",
    " \n",
    "Wor ld-Wide Web : WWW  provides rich, world -wide, on -line information \n",
    "services , where  data objects  are linked  together  to facilitate  interactive  access.  \n",
    "Some  examples  of distributed i nformation services associated with the World -\n",
    "Wide Web include America  Online  Yaho o!, AltaVista,  and Prodigy.  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "num_clusters=math.ceil(len(text)/3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l=text.split(\". \")\n",
    "# import re\n",
    "# l=re.split(r'\\. |\\n',text)\n",
    "# i=0\n",
    "# while i<len(l):\n",
    "#   if len(l[i])<=25:\n",
    "#     l.remove(l[i])\n",
    "#   else:\n",
    "#     i=i+1\n",
    "# l\n",
    "from nltk.tokenize import sent_tokenize\n",
    "l=sent_tokenize(text)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "bert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "sentence_embeddings = bert_model.encode(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import textdistance  # Make sure to install this library using: pip install textdistance\n",
    "\n",
    "# Sample string l\n",
    "# l = [\"apple\", \"banana\", \"orange\", \"grape\", \"cherry\", \"pineapple\", \"blueberry\", \"strawberry\"]\n",
    "\n",
    "# Function to calculate Levenshtein distance between two strings\n",
    "# def levenshtein_distance(str1, str2):\n",
    "#     return textdistance.levenshtein.normalized_distance(str1, str2)\n",
    "\n",
    "# Convert string l to a matrix of token counts\n",
    "# vectorizer = TfidfVectorizer(analyzer='char', use_idf=False)\n",
    "# X = vectorizer.fit_transform(l).toarray()\n",
    "\n",
    "# Calculate pairwise Levenshtein distances\n",
    "# distances = np.zeros((len(l), len(l)))\n",
    "# for i in range(len(l)):\n",
    "#     for j in range(i+1, len(l)):\n",
    "#         distances[i, j] = distances[j, i] = levenshtein_dist(l[i], l[j])\n",
    "\n",
    "distances=cosine_similarity(sentence_embeddings, sentence_embeddings)\n",
    "# for i in range(len(l)):\n",
    "#     for j in range(len(l)):\n",
    "#         distances[i][j]=1-distances[i][j]\n",
    "\n",
    "for i in range(len(l)):\n",
    "    distances[i][i]=0\n",
    "\n",
    "# Perform k-means clustering\n",
    "# num_clusters = 6  # You can adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(distances)\n",
    "\n",
    "# Add cluster labels to the original l\n",
    "cluster_labels = kmeans.labels_\n",
    "# result = pd.DataFrame({'String': l, 'Cluster': cluster_labels})\n",
    "# m=max(cluster_labels)+1\n",
    "# d={}\n",
    "# d2={}\n",
    "# for i in range(len(cluster_labels)):\n",
    "#   x=d.get(cluster_labels[i],\"\")+l[i]+\". \"\n",
    "#   if(len(x)>1200):\n",
    "#     if(cluster_labels[i] in d2):\n",
    "#       d[d2[cluster_labels[i]]]=d[d2[cluster_labels[i]]]+l[i]+\". \"\n",
    "#     else:\n",
    "#       d2[cluster_labels[i]]=m\n",
    "#       d[m]=l[i]+\". \"\n",
    "#       m+=1\n",
    "#   else:\n",
    "#     d[cluster_labels[i]]=x\n",
    "\n",
    "d={}\n",
    "for i in range(len(cluster_labels)):\n",
    "  d[cluster_labels[i]]=d.get(cluster_labels[i],\"\")+l[i]+\". \"\n",
    "\n",
    "# Display the result\n",
    "# print(result)\n",
    "l2=list(d.values())\n",
    "def split_long_strings(strings, max_length):\n",
    "    result = []\n",
    "    for string in strings:\n",
    "        if len(string) > max_length:\n",
    "            # Split the long string into parts of max_length\n",
    "            # parts = [string[i:i+max_length] for i in range(0, len(string), max_length)]\n",
    "            strs=sent_tokenize(string)\n",
    "            str1=strs[0]\n",
    "            for i in range(1,len(strs)):\n",
    "                if(len(str1+strs[i])<=max_length):\n",
    "                    str1+=strs[i]\n",
    "                else:\n",
    "                    result.append(str1)\n",
    "                    str1=strs[i]\n",
    "            result.append(str1)\n",
    "        else:\n",
    "            result.append(string)\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "cluster_list = split_long_strings(l2,3500)\n",
    "cluster_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate,  LLMChain\n",
    "def generate_summary(text_chunk):\n",
    "    # Defining the template to generate summary\n",
    "    template = \"\"\"\n",
    "    Context:\n",
    "    Give one line summary\n",
    "    Input text:\n",
    "    ```{text}```\n",
    "    SUMMARY:\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "    summary = llm_chain.run(text_chunk)\n",
    "    torch.cuda.empty_cache()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymongo\n",
    "!/opt/conda/bin/python3.10 -m pip install \"pymongo[srv]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "connection_string=datasec[\"data\"]\n",
    "client = MongoClient(connection_string)\n",
    "db = client.Llama2\n",
    "collection = db.summary\n",
    "query_criteria = {\"_id\": ObjectId(id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# chunk_summaries = []\n",
    "torch.cuda.empty_cache()\n",
    "import os\n",
    "\n",
    "combined_summary=\"\"\n",
    "prev=\"\"\n",
    "# Set the max_split_size_mb environment variable\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:50'\n",
    "for chunk in cluster_list:\n",
    "    summary = generate_summary(prev+chunk)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(summary)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"done\")\n",
    "    torch.cuda.empty_cache()\n",
    "    # Clear CUDA memory after each iteration\n",
    "    # sumlist=re.split(r'\\. |\\.\\n', summary)\n",
    "    # prev=sumlist[0][:280]+\". \"\n",
    "    # sumlist=summary.split(\"\\n\")\n",
    "    sumlist=sent_tokenize(summary)\n",
    "    prev=\"\"\n",
    "    for i in sumlist:\n",
    "        if len(prev+i)<=800:\n",
    "            prev+=i\n",
    "    # prev=sumlist[0][:800]+\". \"\n",
    "    combined_summary+=summary+\"\\n\"\n",
    "    \n",
    "    update_query = {\"$set\": {\"summary\": combined_summary}}\n",
    "    collection.update_one(query_criteria, update_query)\n",
    "    # chunk_summaries.append(summary)\n",
    "\n",
    "\n",
    "# combined_summary = \"\\n\".join(chunk_summaries)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_summary)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
